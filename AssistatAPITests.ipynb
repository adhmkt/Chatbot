{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assistants API Beta\n",
    "The Assistants API allows you to build AI assistants within your own applications. An Assistant has instructions and can leverage models, tools, and knowledge to respond to user queries. The Assistants API currently supports three types of tools: Code Interpreter, Retrieval, and Function calling. In the future, we plan to release more OpenAI-built tools, and allow you to provide your own tools on our platform.\n",
    "\n",
    "You can explore the capabilities of the Assistants API using the Assistants playground or by building a step-by-step integration outlined in this guide. At a high level, a typical integration of the Assistants API has the following flow:\n",
    "\n",
    "Create an Assistant in the API by defining its custom instructions and picking a model. If helpful, enable tools like Code Interpreter, Retrieval, and Function calling.\n",
    "Create a Thread when a user starts a conversation.\n",
    "Add Messages to the Thread as the user ask questions.\n",
    "Run the Assistant on the Thread to trigger responses. This automatically calls the relevant tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Create an Assistant\n",
    "An Assistant represents an entity that can be configured to respond to users’ Messages using several parameters like:\n",
    "\n",
    "Instructions: how the Assistant and model should behave or respond\n",
    "Model: you can specify any GPT-3.5 or GPT-4 models, including fine-tuned models. The Retrieval tool requires gpt-3.5-turbo-1106 and gpt-4-1106-preview models.\n",
    "Tools: the API supports Code Interpreter and Retrieval that are built and hosted by OpenAI.\n",
    "Functions: the API allows you to define custom function signatures, with similar behavior as our function calling feature.\n",
    "In this example, we're creating an Assistant that is a personal math tutor, with the Code Interpreter tool enabled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "with open('config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "    my_api_key = config['openai_api_key']\n",
    "\n",
    "client = OpenAI(api_key=my_api_key)\n",
    "assistant_id = 'asst_SFJ785rxK4BFeVaWhDPTs7Yb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# response = client.images.generate(\n",
    "#   model=\"dall-e-3\",\n",
    "#   prompt=\"Neymar eating potato salad with Lionel Messi\",\n",
    "#   size=\"1024x1024\",\n",
    "#   quality=\"hd\",\n",
    "#   n=1,\n",
    "# )\n",
    "\n",
    "# image_url = response.data[0].url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-h7znNbCg52cEm2jpdeFAyFfB/user-3SUZXX5l1n9n35qrMV1yVJ3N/img-YkzV7QXaxJRRe81n4dPY8Fy8.png?st=2023-12-29T12%3A32%3A13Z&se=2023-12-29T14%3A32%3A13Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-12-29T06%3A03%3A12Z&ske=2023-12-30T06%3A03%3A12Z&sks=b&skv=2021-08-06&sig=EkM%2BmyeCW6dZPN6V8QanqcJT8XwMAMhnZCMWKPYk36U%3D\n"
     ]
    }
   ],
   "source": [
    "# print(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_SFJ785rxK4BFeVaWhDPTs7Yb', created_at=1703975241, description=None, file_ids=['file-y39i4qdTROHLPkQgdybAfOuH'], instructions='Your are a helpful assistant. You will respond to questions about Amazon Web Services, based on the documentation (files) made available to you.', metadata={}, model='gpt-4-1106-preview', name='The AWS Elastic Beanstalk Developer Guide', object='assistant', tools=[ToolCodeInterpreter(type='code_interpreter'), ToolRetrieval(type='retrieval')])\n",
      "The AWS Elastic Beanstalk Developer Guide\n",
      "gpt-4-1106-preview\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "#assistant = client.beta.assistants.create(\n",
    "#    name=\"Math Tutor\",\n",
    "#    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n",
    "#    tools=[{\"type\": \"code_interpreter\"}],\n",
    "#    model=\"gpt-4-1106-preview\"\n",
    "#)\n",
    "\n",
    "my_assistant = client.beta.assistants.retrieve(assistant_id)\n",
    "print(my_assistant)\n",
    "print(my_assistant.name)\n",
    "print(my_assistant.model)\n",
    "\n",
    "print(my_assistant.metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Create a Thread\n",
    "A Thread represents a conversation. We recommend creating one Thread per user as soon as the user initiates the conversation. Pass any user-specific context and files in this thread by creating Messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threads don’t have a size limit. You can add as many Messages as you want to a Thread. The Assistant will ensure that requests to the model fit within the maximum context window, using relevant optimization techniques such as truncation which we have tested extensively with ChatGPT. When you use the Assistants API, you delegate control over how many input tokens are passed to the model for any given Run, this means you have less control over the cost of running your Assistant in some cases but do not have to deal with the complexity of managing the context window yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Add a Message to a Thread\n",
    "A Message contains text, and optionally any files that you allow the user to upload. Messages need to be added to a specific Thread. Adding images via message objects like in Chat Completions using GPT-4 with Vision is not supported today, but we plan to add support for them in the coming months. You can still upload images and have them processes via retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Please finish this : The AWS Elastic Beanstalk Python platform is a set of platform versions for Python web applications that can run ...\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Run the Assistant\n",
    "For the Assistant to respond to the user message, you need to create a Run. This makes the Assistant read the Thread and decide whether to call tools (if they are enabled) or simply use the model to best answer the query. As the run progresses, the assistant appends Messages to the thread with the role=\"assistant\". The Assistant will also automatically decide what previous Messages to include in the context window for the model. This has both an impact on pricing as well as model performance. The current approach has been optimized based on what we learned building ChatGPT and will likely evolve over time.\n",
    "\n",
    "You can optionally pass new instructions to the Assistant while creating the Run but note that these instructions override the default instructions of the Assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message=\" The name os the user is Fernando. Always greet with by name. He is a premium customer\"\n",
    "\n",
    "\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=my_assistant.id,\n",
    "  instructions = my_assistant.instructions + add_message,\n",
    "  \n",
    "  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Check the Run status\n",
    "By default, a Run goes into the queued state. You can periodically retrieve the Run to check on its status to see if it has moved to completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "Run(id='run_sgCVK2otGl2cDD8q0QvouuCW', assistant_id='asst_SFJ785rxK4BFeVaWhDPTs7Yb', cancelled_at=None, completed_at=1703978166, created_at=1703978150, expires_at=None, failed_at=None, file_ids=['file-y39i4qdTROHLPkQgdybAfOuH'], instructions='Your are a helpful assistant. You will respond to questions about Amazon Web Services, based on the documentation (files) made available to you. The name os the user is Fernando. Always greet with by name. He is a premium customer', last_error=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=1703978150, status='completed', thread_id='thread_YHifyKwNgETISg7zK8eGfS2I', tools=[ToolAssistantToolsCode(type='code_interpreter'), ToolAssistantToolsRetrieval(type='retrieval')])\n"
     ]
    }
   ],
   "source": [
    "run = client.beta.threads.runs.retrieve(\n",
    "  thread_id=thread.id,\n",
    "  run_id=run.id\n",
    ")\n",
    "print(run.status)\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Display the Assistant's Response\n",
    "Once the Run completes, you can list the Messages added to the Thread by the Assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"SyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_GkYGt3CLsIywLGCGz58vBfob', assistant_id='asst_SFJ785rxK4BFeVaWhDPTs7Yb', content=[MessageContentText(text=Text(annotations=[TextAnnotationFileCitation(end_index=702, file_citation=TextAnnotationFileCitationFileCitation(file_id='file-y39i4qdTROHLPkQgdybAfOuH', quote='The AWS Elastic Beanstalk Python platform is a set of platform versions for Python web applications that can run behind a proxy server with WSGI. Each platform branch corresponds to a version of Python such as Python 3.8.   Starting with Amazon Linux 2 platform branches Elastic Beanstalk provides Gunicorn as the default WSGI server.   You can add a Procfile to your source bundle to specify and con\\ufb01gure the WSGI server for your application. For details see the section called \\u201cProc\\ufb01le\\u201d.   You can use the Pipfile and Pipfile.lock \\ufb01les created by Pipenv to specify Python package dependencies and other requirements. For details about specifying dependencies see the section called \\u201cSpecifying dependencies\\u201d.   Elastic Beanstalk provides con\\ufb01guration options that you can use to customize the software tha'), start_index=692, text='\\u30107\\u2020source\\u3011', type='file_citation')], value='Hello Fernando,\\\\n\\\\nThe AWS Elastic Beanstalk Python platform is a set of platform versions for Python web applications that can run behind a proxy server with WSGI. Each platform branch corresponds to a version of Python, such as Python 3.8. Starting with Amazon Linux 2 platform branches, Elastic Beanstalk provides Gunicorn as the default WSGI server.\\\\n\\\\nFurthermore, you can add a Procfile to your source bundle to specify and configure the WSGI server for your application, and use the Pipfile and Pipfile.lock files created by Pipenv to specify Python package dependencies and other requirements. Elastic Beanstalk also provides configuration options that allow you to customize the software\\u30107\\u2020source\\u3011.'), type='text')], created_at=1703978160, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_sgCVK2otGl2cDD8q0QvouuCW', thread_id='thread_YHifyKwNgETISg7zK8eGfS2I'), ThreadMessage(id='msg_OfiIen6A8CkiTEIv2IXngCiW', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='Please finish this : The AWS Elastic Beanstalk Python platform is a set of platform versions for Python web applications that can run ...'), type='text')], created_at=1703978139, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_YHifyKwNgETISg7zK8eGfS2I')], object='list', first_id='msg_GkYGt3CLsIywLGCGz58vBfob', last_id='msg_OfiIen6A8CkiTEIv2IXngCiW', has_more=False)\"\n"
     ]
    }
   ],
   "source": [
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "json_string = json.dumps(messages, default=custom_serializer, indent=4)\n",
    "print(json_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract and print messages\n",
    "def extract_messages(data_str):\n",
    "    # Splitting by '), type='text')],' to isolate each message\n",
    "    messages = data_str.split(\"'), type='text')],\")[0:-1]  # Skip the last split as it's not a message\n",
    "\n",
    "    for msg in messages:\n",
    "        # Finding the start of the content value\n",
    "        content_start = msg.rfind(\"value='\") + len(\"value='\")\n",
    "        if content_start == -1 + len(\"value='\"):  # If not found, try the other quotation mark style\n",
    "            content_start = msg.rfind('value=\\\"') + len('value=\\\"')\n",
    "\n",
    "        # Extract content up to the end (excluding '), type='text')],')\n",
    "        content = msg[content_start:]\n",
    "\n",
    "        # Removing any leading or trailing whitespace or control characters\n",
    "        content = content.strip()\n",
    "\n",
    "        # Determining if it's a user or bot message\n",
    "        role = 'Bot' if \"assistant_id='\" in msg else 'User'\n",
    "\n",
    "        # Printing the extracted content\n",
    "        print(f\"{role}: {content}\")\n",
    "\n",
    "# Calling the function with the data string\n",
    "#extract_messages(data_string)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hello Fernando,\\\\n\\\\nThe AWS Elastic Beanstalk Python platform is a set of platform versions for Python web applications that can run behind a proxy server with WSGI. Each platform branch corresponds to a version of Python, such as Python 3.8. Starting with Amazon Linux 2 platform branches, Elastic Beanstalk provides Gunicorn as the default WSGI server.\\\\n\\\\nFurthermore, you can add a Procfile to your source bundle to specify and configure the WSGI server for your application, and use the Pipfile and Pipfile.lock files created by Pipenv to specify Python package dependencies and other requirements. Elastic Beanstalk also provides configuration options that allow you to customize the software\\u30107\\u2020source\\u3011.\n",
      "User: Please finish this : The AWS Elastic Beanstalk Python platform is a set of platform versions for Python web applications that can run ...\n"
     ]
    }
   ],
   "source": [
    "extract_messages(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def format_conversation(json_string):\n",
    "    # Decode the JSON string\n",
    "    decoded_string = json.loads(json_string)\n",
    "    \n",
    "    # Regular expression to match \"User:\" and \"Bot:\"\n",
    "    pattern = r\"(User:|Bot:)\"\n",
    "\n",
    "    # Split the string into messages\n",
    "    messages = re.split(pattern, decoded_string)\n",
    "\n",
    "    # Initialize an empty list to hold formatted messages\n",
    "    formatted_messages = []\n",
    "\n",
    "    # Iterate over the messages and format them\n",
    "    for i in range(1, len(messages), 2):\n",
    "        speaker = messages[i].strip()\n",
    "        text = messages[i + 1].strip().replace(\"\\\\n\", \"\\n\")\n",
    "        formatted_message = f\"**{speaker}:** {text}\"\n",
    "        formatted_messages.append(formatted_message)\n",
    "\n",
    "    # Join all formatted messages\n",
    "    return \"\\n\\n\".join(formatted_messages)\n",
    "\n",
    "# Example usage\n",
    "# json_string = '{\"text\":\"Bot: Durante a Segunda Guerra Mundial, Get\\\\u00falio Vargas adotou uma postura que demonstra a compreens\\\\u00e3o da import\\\\u00e2ncia da ind\\\\u00fastria para a defesa nacional...\"}'\n",
    "# formatted_text = format_conversation(json_string)\n",
    "# print(formatted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hello Fernando,\\\\n\\\\nThe AWS Elastic Beanstalk Python platform is a set of platform versions for Python web applications that can run behind a proxy server with WSGI. Each platform branch corresponds to a version of Python, such as Python 3.8. Starting with Amazon Linux 2 platform branches, Elastic Beanstalk provides Gunicorn as the default WSGI server.\\\\n\\\\nFurthermore, you can add a Procfile to your source bundle to specify and configure the WSGI server for your application, and use the Pipfile and Pipfile.lock files created by Pipenv to specify Python package dependencies and other requirements. Elastic Beanstalk also provides configuration options that allow you to customize the software\\u30107\\u2020source\\u3011.\n",
      "User: Please finish this : The AWS Elastic Beanstalk Python platform is a set of platform versions for Python web applications that can run ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_text = extract_messages(json_string)\n",
    "formatted_text = format_conversation(json_string)\n",
    "print(formatted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"You are an assistant with access to specific reference materials. When responding to questions, use only the information provided in the linked files as your source. Do not provide answers based on general knowledge or external sources. Your responses should be directly based on, and limited to, the content and information contained within these files. If a query cannot be answered with the information in the files, respond with 'The answer to this question is not available in my current resources.' Focus on accuracy and relevance to the content of the files in all your responses.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(my_assistant.instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.audio.speech.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"alloy\",\n",
    "    input=\"Satyrday morning, I'm here with my son, watching Breaking Bad on Netflix\",\n",
    ")\n",
    "\n",
    "response.stream_to_file(\"output.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='This image depicts a desert landscape, characterized by red sandstone formations, which could be indicative of regions like the American Southwest. A dirt path winds through the foreground, leading towards the rock formations. The vegetation is sparse and consists of low shrubs and dry grasses, typical of arid climates. In the background, a blue sky with some puffy white clouds contrasts with the warm colors of the earth and rocks. The lighting suggests the photo was taken in the late afternoon, with the sun casting a warm glow on the landscape.', role='assistant', function_call=None, tool_calls=None))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4-vision-preview\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"What’s in this image?\"},\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": \"https://i.pinimg.com/originals/a6/9d/5e/a69d5ecb0ddca9f2f91a3dbf71fc179c.jpg\",\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ],\n",
    "  max_tokens=300,\n",
    ")\n",
    "\n",
    "audio_response = client.audio.speech.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"alloy\",\n",
    "    input=response.choices[0].message.content  # Directly use the content here\n",
    ")\n",
    "\n",
    "\n",
    "audio_response.stream_to_file(\"output2.mp3\")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-8bTXw2AJVLNcBChGVtpjeHqVshVDD', 'object': 'chat.completion', 'created': 1703942404, 'model': 'gpt-4-1106-vision-preview', 'usage': {'prompt_tokens': 268, 'completion_tokens': 79, 'total_tokens': 347}, 'choices': [{'message': {'role': 'assistant', 'content': 'The image shows a stylized graphic that resembles a coin or a medallion with an emblem that combines elements of technology and circuitry. Centered is an icon that suggests a tree or a brain made from electronic circuits, evoking concepts like artificial intelligence, technology, or futuristic themes. The color scheme is primarily blue with light blue highlights, which gives it a digital or cyber-feel.'}, 'finish_reason': 'stop', 'index': 0}]}\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import requests\n",
    "\n",
    "# OpenAI API Key\n",
    "api_key = \"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\"\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"static/images/logo.png\"\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "payload = {\n",
    "  \"model\": \"gpt-4-vision-preview\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"What’s in this image?\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"max_tokens\": 300\n",
    "}\n",
    "\n",
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image depicts a desert landscape, characterized by red sandstone formations which could be indicative of regions like the American Southwest. A dirt path winds through the foreground, leading towards the rock formations. The vegetation is sparse and consists of low shrubs and dry grasses, typical of arid climates. In the background, a blue sky with some puffy white clouds contrasts with the warm colors of the earth and rocks. The lighting suggests the photo was taken in the late afternoon, with the sun casting a warm glow on the landscape.\n"
     ]
    }
   ],
   "source": [
    "audio_file= open(\"output2.mp3\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\", \n",
    "  file=audio_file,\n",
    "  \n",
    ")\n",
    "\n",
    "print(transcript.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-h7znNbCg52cEm2jpdeFAyFfB/user-3SUZXX5l1n9n35qrMV1yVJ3N/img-Sg4qA4vBW6JjH4vA6CgUzOod.png?st=2024-01-06T13%3A34%3A14Z&se=2024-01-06T15%3A34%3A14Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-01-05T21%3A03%3A13Z&ske=2024-01-06T21%3A03%3A13Z&sks=b&skv=2021-08-06&sig=UMoxhYgn1ld1q3aun3EUnm0vlatqrMTVDFfIhwp6ZTc%3D\n"
     ]
    }
   ],
   "source": [
    "blob = \"\"\"\"\n",
    "You are a kaway coloring book image generator. All images you create should be whaite wthi black outline\n",
    "magine a charming illustration where the centerpiece is a delightful baby panda with large, sparkling eyes that exude innocence and wonder. The baby panda's fur would be a fluffy texture that's almost tangible, with patches of black and white that are classic and cuddly.\n",
    "This panda cub would be situated in the middle of a lush, enchanting bamboo forest. The bamboo stalks would tower above, with oversized leaves that create a whimsical canopy overhead. These leaves would be designed with bold, simple lines to make them easy for young children to color. Some of the bamboo stalks could have gentle curves, giving the impression of a forest that's alive and swaying to a gentle breeze.\n",
    "Around the panda, you'd find an undergrowth of smaller plants and flowers, exaggerated in size to match the kawaii aesthetic. Each flower would have a friendly face, adding to the magical atmosphere of the scene. The panda itself could be holding or interacting with a plump bamboo shoot, with a facial expression full of joy and satisfaction.\n",
    "For an extra touch of adorableness, perhaps a few tiny insects like ladybugs or butterflies with oversized, doe-like eyes could be perched on the bamboo or fluttering around the panda, as if they too are captivated by its charm.\n",
    "The background would be kept simple yet engaging, with soft clouds in the sky and maybe the hint of a distant mountain range, ensuring that the focal point remains on our cute baby panda and the magical bamboo forest surroundings.\n",
    "This scene would be outlined in bold, clear lines to provide a satisfying coloring experience for young children and to emphasize the cuteness of the elements.\n",
    "\"\"\"\n",
    "\n",
    "response = client.images.generate(\n",
    "  model=\"dall-e-3\",\n",
    "  prompt=blob,\n",
    "  size=\"1024x1024\",\n",
    "  quality=\"standard\",\n",
    "  n=1,\n",
    ")\n",
    "\n",
    "image_url = response.data[0].url\n",
    "print(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-h7znNbCg52cEm2jpdeFAyFfB/user-3SUZXX5l1n9n35qrMV1yVJ3N/img-ipYpaotPJ2isdSRbxZClv4qt.png?st=2024-01-06T13%3A29%3A49Z&se=2024-01-06T15%3A29%3A49Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-01-06T01%3A46%3A47Z&ske=2024-01-07T01%3A46%3A47Z&sks=b&skv=2021-08-06&sig=qAFxgrMTeqUEaGZa/THpK37zrO5JMnKfckttMUQG03Q%3D\n"
     ]
    }
   ],
   "source": [
    "print(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-h7znNbCg52cEm2jpdeFAyFfB/user-3SUZXX5l1n9n35qrMV1yVJ3N/img-JYyor76vWIfeZdsE3CWWxWil.png?st=2023-12-31T20%3A13%3A10Z&se=2023-12-31T22%3A13%3A10Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-12-31T15%3A14%3A42Z&ske=2024-01-01T15%3A14%3A42Z&sks=b&skv=2021-08-06&sig=KIxJS/aDkBkTNz0BWdNyb8YJiE762WGDryx5nJg0LsY%3D\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Display the image\n",
    "display(Image(url=image_url))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
